# -*- coding: utf-8 -*-
"""lg_aimers

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q4Vl6-CxVrpKK6jPx96nlkdbySlXpXxo
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# GPU 설정
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
if tf.config.experimental.list_physical_devices('GPU'):
    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)

data_path = "/content/drive/MyDrive/lg_data/train.csv"
test_path = "/content/drive/MyDrive/lg_data/test.csv"

df = pd.read_csv(data_path, encoding="utf-8-sig")
test_df = pd.read_csv(test_path, encoding="utf-8-sig")

df.columns = df.columns.str.strip()
test_df.columns = test_df.columns.str.strip()

# 불필요한 컬럼 제거
drop_columns = ["ID", "시술 시기 코드"]
df = df.drop(columns=drop_columns)
test_df = test_df.drop(columns=drop_columns)

print(df.columns.tolist())  # 컬럼명을 리스트 형태로 출력

from sklearn.preprocessing import LabelEncoder

# 범주형 데이터 컬럼 목록 확인
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()

# LabelEncoder 저장용 딕셔너리
label_encoders = {}

for col in categorical_columns:
    le = LabelEncoder()

    # 훈련 데이터로 Label Encoding 학습
    df[col] = le.fit_transform(df[col].astype(str))
    label_encoders[col] = le

    # 🛠 **테스트 데이터 변환 시 예외 처리**
    test_df[col] = test_df[col].astype(str).apply(lambda x: x if x in le.classes_ else "Unknown")

    # 새로운 값이 생기면 기존 classes에 추가 후 변환
    le.classes_ = np.append(le.classes_, "Unknown")
    test_df[col] = le.transform(test_df[col])

# "임신 성공 여부" 컬럼이 훈련 데이터(df)에는 있지만, 테스트 데이터(test_df)에는 없음
# ✅ X_train, y_train 분리
X_train = df.drop(columns=["임신 성공 여부"])  # 입력 데이터
y_train = df["임신 성공 여부"]  # 타겟 변수

# ✅ X_test는 test_df에서 동일한 입력 데이터만 사용
X_test = test_df  # test_df에는 "임신 성공 여부" 컬럼이 없으므로 그대로 사용

print("✅ X_train 컬럼 목록:", X_train.columns.tolist())
print("✅ X_test 컬럼 목록:", X_test.columns.tolist())  # 비교 확인

from sklearn.preprocessing import LabelEncoder

# 범주형 컬럼 찾기
categorical_columns = X_train.select_dtypes(include=['object']).columns.tolist()

# 각 컬럼에 대해 Label Encoding 수행
label_encoders = {}

for col in categorical_columns:
    le = LabelEncoder()

    # 훈련 데이터에 Label Encoding 적용
    X_train[col] = le.fit_transform(X_train[col].astype(str))

    # 테스트 데이터에도 동일한 Label Encoding 적용 (예외처리 포함)
    X_test[col] = X_test[col].astype(str).apply(lambda x: x if x in le.classes_ else "Unknown")
    le.classes_ = np.append(le.classes_, "Unknown")  # 새로운 값 처리
    X_test[col] = le.transform(X_test[col])

    # Label Encoder 저장
    label_encoders[col] = le

print("✅ 범주형 데이터 Label Encoding 완료!")

from sklearn.preprocessing import StandardScaler

# 숫자형 컬럼 선택
numeric_columns = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()

# StandardScaler 적용
scaler = StandardScaler()
X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])
X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])  # 테스트 데이터도 동일 변환

print("✅ 데이터 정규화 완료!")

from sklearn.model_selection import train_test_split

# 훈련 데이터 (80%) / 검증 데이터 (20%) 분할
X_train_final, X_val, y_train_final, y_val = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42
)

print("✅ 훈련 데이터 크기:", X_train_final.shape)
print("✅ 검증 데이터 크기:", X_val.shape)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# 모델 정의
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_final.shape[1],)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')  # 이진 분류이므로 sigmoid 사용
])

# 모델 컴파일
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# EarlyStopping 설정 (과적합 방지)
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# 모델 학습
model.fit(X_train_final, y_train_final,
          validation_data=(X_val, y_val),
          epochs=50, batch_size=32,
          callbacks=[early_stopping], verbose=1)

print("✅ 모델 학습 완료!")

# 검증 데이터 평가
val_loss, val_acc = model.evaluate(X_val, y_val)
print(f"검증 데이터 손실값: {val_loss:.4f}")
print(f"검증 데이터 정확도(Accuracy): {val_acc:.4f}")

# 테스트 데이터 예측값 계산
test_predictions = model.predict(X_test)
test_predictions = (test_predictions > 0.5).astype(int)

# 테스트 데이터 예측값 분포 확인
print("✅ 테스트 데이터 예측값 분포:")
print(pd.Series(test_predictions.flatten()).value_counts())

# 훈련 데이터에서 예측값 생성
y_train_pred = model.predict(X_train)
y_train_pred = (y_train_pred > 0.5).astype(int)  # 확률을 0 또는 1로 변환

# 훈련 데이터에서 성공(1)의 비율
train_success_ratio = y_train_pred.mean()

# 테스트 데이터에서 성공(1)의 비율
test_success_ratio = test_predictions.mean()

print(f"✅ 훈련 데이터에서 성공 비율: {train_success_ratio:.4f}")
print(f"✅ 테스트 데이터에서 성공 비율: {test_success_ratio:.4f}")
print(f"✅ 두 데이터셋의 비율 차이: {abs(train_success_ratio - test_success_ratio):.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
plt.hist(y_train_pred, bins=2, alpha=0.5, label="훈련 데이터 예측값")
plt.hist(test_predictions, bins=2, alpha=0.5, label="테스트 데이터 예측값")
plt.xticks([0, 1], ["임신 실패(0)", "임신 성공(1)"])
plt.xlabel("예측 결과")
plt.ylabel("샘플 개수")
plt.title("훈련 데이터 vs 테스트 데이터 예측값 비교")
plt.legend()
plt.show()

